{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Ethereum Blockchain Arbitrages and Liquidations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-09T15:52:38.062845Z",
     "end_time": "2023-04-09T15:52:38.262235Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection\n",
    "\n",
    "The data consists of a list of arbitrage transactions, liquidations, block features which are stored on a postgres db.\n",
    "Additionally, general features of the blockchain e.g. number of protocol usages in the transactions are stored in the db directory.\n",
    "The arbitrage transactions were collected using calls to multiple Erigon RPC endpoints.\n",
    "\n",
    "The first collection of data is from block 15200000 to 15500000 or from Jul-23-2022 04:32:35 PM +UTC to Sep-09-2022 01:39:42 AM +UTC.\n",
    "These blocks are pre-merge blocks. The next collection will analyse the post-merge blocks.\n",
    "\n",
    "First, we must connect to our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Connect to db\n",
    "from db import get_inspect_database_uri, _get_engine\n",
    "\n",
    "engine = _get_engine(get_inspect_database_uri())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T16:02:13.469144Z",
     "end_time": "2023-04-09T16:02:13.546545Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Arbitrage Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM arbitrages WHERE block_number BETWEEN 15200000 AND 15500000\"\n",
    "arb_df = pd.read_sql_query(query, engine)\n",
    "arb_df.set_index('id', inplace=True)\n",
    "arb_df['timestamp'] = pd.to_datetime(arb_df['timestamp'])\n",
    "arb_df = arb_df.sort_values('block_number')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T16:16:09.469480Z",
     "end_time": "2023-04-09T16:16:10.671673Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "                                     transaction_hash  block_number   \nid                                                                    \n34  0xd39500706630fb26ea405ce04d7b5884df0866cb1a1c...      15200022  \\\n35  0x63c9c17d97c181b8819783b599a59940a786b5bd2bb6...      15200028   \n37  0xc9c502aec6b07d452ed4ce1e35c20e6cea0cda91e21a...      15200029   \n36  0x2eb09482b29b2d32a240142dee1e7ec6288719c7f049...      15200029   \n38  0x7acd0000e5e346c66e58aac81c4f48ad6022c6a0184c...      15200034   \n\n             timestamp                             account_address  status   \nid                                                                           \n34 2022-07-23 21:08:45  0xd8c7031da609a6e201e038dd11c97d7f26f1d572    True  \\\n35 2022-07-23 21:09:18  0xd7c09e006a2891880331b0f6224071c1e890a98a    True   \n37 2022-07-23 21:09:57  0x5aa3393e361c2eb342408559309b3e873cd876d6    True   \n36 2022-07-23 21:09:57  0xe8c060f8052e07423f71d445277c61ac5138a2e5    True   \n38 2022-07-23 21:11:19  0xd8c7031da609a6e201e038dd11c97d7f26f1d572    True   \n\n                                    contracts_address   \nid                                                      \n34  {0xfca9090d2c91e11cc546b0d7e4918c79e0088194,0x...  \\\n35  {0x2c51eaa1bcc7b013c3f1d5985cdcb3c56dc3fbc1,0x...   \n37  {0xb404057ee4b1d7359ca5a57ac1c020b74c23e56b,0x...   \n36  {0x06db071bebeb0570a8f3aa0e49238140bedc268f,0x...   \n38  {0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640,0x...   \n\n                                 input_tokens_address   \nid                                                      \n34  {0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...  \\\n35  {0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...   \n37  {0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...   \n36  {0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...   \n38  {0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...   \n\n                                  input_tokens_amount   \nid                                                      \n34   {5120123648171978000,10837504868.0,7798609065.0}  \\\n35       {240470594654432770,22176822844245777000000}   \n37        {1906092123352685000,105673083691328340000}   \n36  {203776686158774270,2011097854535.0,1272233986...   \n38  {6483562585462506000,9898566457.0,120839032289...   \n\n                                output_tokens_address   \nid                                                      \n34  {0x70e8de73ce538da2beed35d14187f6959a8eca96,0x...  \\\n35  {0x2d94aa3e47d9d5024503ca8491fce9a2fb4da198,0x...   \n37  {0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9,0x...   \n36  {0x53fd2342b43ecd24aef1535bc3797f509616ce8c,0x...   \n38  {0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48,0x...   \n\n                                 output_tokens_amount   \nid                                                      \n34   {10837504868.0,7798609065.0,5133779858359948000}  \\\n35       {22176822844245777000000,248404143686549860}   \n37        {105673083691328340000,1939547111027948800}   \n36  {2011097854535.0,12722339869926854000000,22747...   \n38  {9898566457.0,120839032289753.0,64965197108999...   \n\n                  protocols  gas_price  gas_usage  block_position   \nid                                                                  \n34             {uniswap_v3}     163839      68917               0  \\\n35             {uniswap_v2}     229745     136481              63   \n37  {uniswap_v3,uniswap_v2}     947727      65768              33   \n36             {uniswap_v2}     474200      37474              37   \n38             {uniswap_v3}     156765      60038               1   \n\n    profit_amount  \nid                 \n34   1.365621e+16  \n35   7.933549e+15  \n37   3.345499e+16  \n36   2.369401e+16  \n38   1.295713e+16  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transaction_hash</th>\n      <th>block_number</th>\n      <th>timestamp</th>\n      <th>account_address</th>\n      <th>status</th>\n      <th>contracts_address</th>\n      <th>input_tokens_address</th>\n      <th>input_tokens_amount</th>\n      <th>output_tokens_address</th>\n      <th>output_tokens_amount</th>\n      <th>protocols</th>\n      <th>gas_price</th>\n      <th>gas_usage</th>\n      <th>block_position</th>\n      <th>profit_amount</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34</th>\n      <td>0xd39500706630fb26ea405ce04d7b5884df0866cb1a1c...</td>\n      <td>15200022</td>\n      <td>2022-07-23 21:08:45</td>\n      <td>0xd8c7031da609a6e201e038dd11c97d7f26f1d572</td>\n      <td>True</td>\n      <td>{0xfca9090d2c91e11cc546b0d7e4918c79e0088194,0x...</td>\n      <td>{0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...</td>\n      <td>{5120123648171978000,10837504868.0,7798609065.0}</td>\n      <td>{0x70e8de73ce538da2beed35d14187f6959a8eca96,0x...</td>\n      <td>{10837504868.0,7798609065.0,5133779858359948000}</td>\n      <td>{uniswap_v3}</td>\n      <td>163839</td>\n      <td>68917</td>\n      <td>0</td>\n      <td>1.365621e+16</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>0x63c9c17d97c181b8819783b599a59940a786b5bd2bb6...</td>\n      <td>15200028</td>\n      <td>2022-07-23 21:09:18</td>\n      <td>0xd7c09e006a2891880331b0f6224071c1e890a98a</td>\n      <td>True</td>\n      <td>{0x2c51eaa1bcc7b013c3f1d5985cdcb3c56dc3fbc1,0x...</td>\n      <td>{0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...</td>\n      <td>{240470594654432770,22176822844245777000000}</td>\n      <td>{0x2d94aa3e47d9d5024503ca8491fce9a2fb4da198,0x...</td>\n      <td>{22176822844245777000000,248404143686549860}</td>\n      <td>{uniswap_v2}</td>\n      <td>229745</td>\n      <td>136481</td>\n      <td>63</td>\n      <td>7.933549e+15</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>0xc9c502aec6b07d452ed4ce1e35c20e6cea0cda91e21a...</td>\n      <td>15200029</td>\n      <td>2022-07-23 21:09:57</td>\n      <td>0x5aa3393e361c2eb342408559309b3e873cd876d6</td>\n      <td>True</td>\n      <td>{0xb404057ee4b1d7359ca5a57ac1c020b74c23e56b,0x...</td>\n      <td>{0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...</td>\n      <td>{1906092123352685000,105673083691328340000}</td>\n      <td>{0x50d1c9771902476076ecfc8b2a83ad6b9355a4c9,0x...</td>\n      <td>{105673083691328340000,1939547111027948800}</td>\n      <td>{uniswap_v3,uniswap_v2}</td>\n      <td>947727</td>\n      <td>65768</td>\n      <td>33</td>\n      <td>3.345499e+16</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>0x2eb09482b29b2d32a240142dee1e7ec6288719c7f049...</td>\n      <td>15200029</td>\n      <td>2022-07-23 21:09:57</td>\n      <td>0xe8c060f8052e07423f71d445277c61ac5138a2e5</td>\n      <td>True</td>\n      <td>{0x06db071bebeb0570a8f3aa0e49238140bedc268f,0x...</td>\n      <td>{0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...</td>\n      <td>{203776686158774270,2011097854535.0,1272233986...</td>\n      <td>{0x53fd2342b43ecd24aef1535bc3797f509616ce8c,0x...</td>\n      <td>{2011097854535.0,12722339869926854000000,22747...</td>\n      <td>{uniswap_v2}</td>\n      <td>474200</td>\n      <td>37474</td>\n      <td>37</td>\n      <td>2.369401e+16</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>0x7acd0000e5e346c66e58aac81c4f48ad6022c6a0184c...</td>\n      <td>15200034</td>\n      <td>2022-07-23 21:11:19</td>\n      <td>0xd8c7031da609a6e201e038dd11c97d7f26f1d572</td>\n      <td>True</td>\n      <td>{0x88e6a0c2ddd26feeb64f039a2c41296fcb3f5640,0x...</td>\n      <td>{0xc02aaa39b223fe8d0a0e5c4f27ead9083c756cc2,0x...</td>\n      <td>{6483562585462506000,9898566457.0,120839032289...</td>\n      <td>{0xa0b86991c6218b36c1d19d4a2e9eb0ce3606eb48,0x...</td>\n      <td>{9898566457.0,120839032289753.0,64965197108999...</td>\n      <td>{uniswap_v3}</td>\n      <td>156765</td>\n      <td>60038</td>\n      <td>1</td>\n      <td>1.295713e+16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arb_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T16:16:15.020242Z",
     "end_time": "2023-04-09T16:16:15.076141Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2023-04-09T16:16:18.283555Z",
     "end_time": "2023-04-09T16:16:18.401532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 114160 entries, 34 to 106593\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   transaction_hash       114160 non-null  object        \n",
      " 1   block_number           114160 non-null  int64         \n",
      " 2   timestamp              114160 non-null  datetime64[ns]\n",
      " 3   account_address        114160 non-null  object        \n",
      " 4   status                 114160 non-null  bool          \n",
      " 5   contracts_address      114160 non-null  object        \n",
      " 6   input_tokens_address   114160 non-null  object        \n",
      " 7   input_tokens_amount    114160 non-null  object        \n",
      " 8   output_tokens_address  114160 non-null  object        \n",
      " 9   output_tokens_amount   114160 non-null  object        \n",
      " 10  protocols              114160 non-null  object        \n",
      " 11  gas_price              114160 non-null  int64         \n",
      " 12  gas_usage              114160 non-null  int64         \n",
      " 13  block_position         114160 non-null  int64         \n",
      " 14  profit_amount          114160 non-null  float64       \n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), int64(4), object(8)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "arb_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Status Analysis\n",
    "\n",
    "Get the success rate of each address and protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_features_grouped_by(df: pd.DataFrame, condition: str, _by: [str], features: [str]) -> pd.DataFrame:\n",
    "    return df.loc[eval(condition)].groupby(by=_by).count().reset_index()[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Address\n",
    "\n",
    "Get the success rate of each address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failed_txns_df = count_features_grouped_by(df=arb_df, condition=\"arb_df['status']==False\", _by=['account_address'],\n",
    "                                           features=['account_address', 'status'])\n",
    "failed_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "passed_txns_df = count_features_grouped_by(df=arb_df, condition=\"arb_df['status']==True\", _by=['account_address'],\n",
    "                                           features=['account_address', 'status'])\n",
    "passed_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df = passed_txns_df.merge(failed_txns_df, how='outer', on='account_address').rename(\n",
    "    columns={\"status_x\": \"pass\", \"status_y\": \"fail\"})\n",
    "\n",
    "del failed_txns_df\n",
    "del passed_txns_df\n",
    "\n",
    "merged_txns_df.fillna(0, inplace=True)\n",
    "merged_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df['success_rate'] = merged_txns_df['pass'] / (merged_txns_df['pass'] + merged_txns_df['fail'])\n",
    "merged_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df.loc[merged_txns_df['success_rate'] < 1].hist(column='success_rate', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_txns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_list_data(row):\n",
    "    row['protocols'] = row['protocols'].split(\";\")\n",
    "    return row\n",
    "\n",
    "\n",
    "def _protocol_use(_protocols) -> {}:\n",
    "    _protocol_uses = {}\n",
    "    for row, _cnt in _protocols.value_counts().iteritems():\n",
    "        for idx in row:\n",
    "            _protocol_uses[idx] = _protocol_uses.get(idx, 0) + _cnt\n",
    "\n",
    "    return _protocol_uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_protocols = arb_df[['transaction_hash', 'protocols', 'status']].apply(_get_list_data, axis=1)\n",
    "_protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_protocols = pd.concat([_protocols, _protocols['protocols'].str.join(',').str.get_dummies(sep=',').astype(bool)],\n",
    "                       axis=1).drop(columns=['protocols'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = list(_protocols.columns)\n",
    "protocols.remove('transaction_hash')\n",
    "protocols.remove('status')\n",
    "protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_protocol_rate(pos_condition: str, neg_condition: str) -> {}:\n",
    "    protocol_success_rate = {}\n",
    "    for protocol in protocols:\n",
    "        failed_cnt = len(_protocols.loc[(_protocols[protocol] == True) & (eval(neg_condition))])\n",
    "        passed_cnt = len(_protocols.loc[(_protocols[protocol] == True) & (eval(pos_condition))])\n",
    "        protocol_success_rate[protocol] = passed_cnt / (passed_cnt + failed_cnt)\n",
    "\n",
    "    return protocol_success_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_rates = _get_protocol_rate(pos_condition=\"_protocols['status']==True\",\n",
    "                                    neg_condition=\"_protocols['status']==False\")\n",
    "protocol_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax1.bar(protocol_rates.keys(), protocol_rates.values(), width=0.5)\n",
    "ax1.set_xticklabels(protocol_rates.keys(), rotation=45)\n",
    "ax1.set_title(\"Protocol Success Rate\")\n",
    "ax1.set_xlabel(\"Protocol\")\n",
    "f.text(0.08, 0.5, 'Success Rate', va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefit Amount Analysis\n",
    "\n",
    "In this part, we analyse the total benefit gained by each arbitrageur and protocol in USD.\n",
    "\n",
    "First, we must get the current rate of each token in the Ethereum blockchain.<br>\n",
    "Note that for an exact benefit value, we must get the price of the token in the same timestamp of the arbitrage transaction. This is a work to be done in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_df[['account_address']].to_csv('arbitrageurs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_features_grouped_by(df: pd.DataFrame, condition: str, _by: [str], features: [str]) -> pd.DataFrame:\n",
    "    return df.loc[eval(condition)].groupby(by=_by).sum().reset_index()[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Wei to ETH\n",
    "arb_df['profit_amount'] /= 1e18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "usd_prices_df = pd.read_csv('usd_rates.csv', names=['token_address', 'usd_price', 'time_stamp'])\n",
    "usd_prices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_txns_df = sum_features_grouped_by(df=arb_df, condition=\"arb_df['profit_amount']<=0\", _by=['account_address'],\n",
    "                                       features=['account_address', 'profit_amount'])\n",
    "profit_txns_df = sum_features_grouped_by(df=arb_df, condition=\"arb_df['profit_amount']>0\", _by=['account_address'],\n",
    "                                         features=['account_address', 'profit_amount'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_txns_df['profit_amount'] *= 1093.98\n",
    "profit_txns_df['profit_amount'] *= 1093.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_txns_df.profit_amount.value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profit_txns_df.hist('profit_amount', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df = profit_txns_df.merge(loss_txns_df, how='outer', on='account_address').rename(\n",
    "    columns={\"profit_amount_x\": \"profit\", \"profit_amount_y\": \"loss\"})\n",
    "\n",
    "del loss_txns_df\n",
    "del profit_txns_df\n",
    "\n",
    "merged_txns_df.fillna(0, inplace=True)\n",
    "merged_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df['total_profit'] = merged_txns_df['profit'] + merged_txns_df['loss']\n",
    "merged_txns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df.hist(column='total_profit', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_txns_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del merged_txns_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_protocols = arb_df[['transaction_hash', 'protocols', 'profit_amount']].apply(_get_list_data, axis=1)\n",
    "_protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_protocols = pd.concat([_protocols, _protocols['protocols'].str.join(',').str.get_dummies(sep=',').astype(bool)],\n",
    "                       axis=1).drop(columns=['protocols'])\n",
    "_protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocols = list(_protocols.columns)\n",
    "protocols.remove('transaction_hash')\n",
    "protocols.remove('profit_amount')\n",
    "protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_success_rate = {}\n",
    "for protocol in protocols:\n",
    "    protocol_success_rate[protocol] = _protocols.loc[(_protocols[protocol] == True)].sum()\n",
    "\n",
    "protocol_success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas Price Analysis\n",
    "\n",
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_df.loc[arb_df['gas_price'] <= 0.2e7].hist(column='gas_price', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_df.hist(column='gas_price', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average gas price per block\n",
    "Compare average gas price for arbitrage transactions in each block with the total average gas price of that block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_gas_db_path = \"../db/avg_gas_price/\"\n",
    "avg_gas_df = pd.concat(\n",
    "    map(lambda file_name: pd.read_csv(avg_gas_db_path + file_name, names=['block_number', 'gas_price'],\n",
    "                                      index_col=False), os.listdir(avg_gas_db_path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_gas_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compared with all transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_gas_df = avg_gas_df.merge(arb_df.groupby(by=['block_number']).mean().reset_index()[['block_number', 'gas_price']],\n",
    "                              how='outer', on='block_number')\n",
    "avg_gas_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_gas_df['gas_price_y'] = avg_gas_df['gas_price_y'].fillna(method='bfill')\n",
    "avg_gas_df['gas_price_y'] = avg_gas_df['gas_price_y'].fillna(method='ffill')\n",
    "avg_gas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_gas_df['block_number'], avg_gas_df['gas_price_x'], '.', label='total_avg')\n",
    "plt.plot(avg_gas_df['block_number'], avg_gas_df['gas_price_y'], '.', label='arb_avg')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "first_quarter_df = avg_gas_df[avg_gas_df['block_number'] < 13500100]\n",
    "plt.plot(first_quarter_df['block_number'], first_quarter_df['gas_price_x'] / first_quarter_df['gas_price_y'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas Usage Analysis\n",
    "\n",
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arb_df.loc[arb_df['gas_usage'] <= 0.3e6].hist(column='gas_usage', bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gas Price - Benefit Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "benefit_gas_df = arb_df[['profit_amount', 'gas_price']]\n",
    "benefit_gas_df.loc[:, 'profit_amount'] *= 1093.98\n",
    "benefit_gas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sorted_benefit_gas_df = benefit_gas_df.sort_values(by='profit_amount', axis=0, inplace=False)\n",
    "del benefit_gas_df\n",
    "sorted_benefit_gas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sorted_benefit_gas_df['profit_amount'], sorted_benefit_gas_df['gas_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_benefit_gas_df['profit_amount'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the Tokens\n",
    "\n",
    "In this part we perform some simple analysis on the collected arbitrages.\n",
    "\n",
    "In the first part, we show the most used tokens for profit in arbitrage.\n",
    "Note that in an arbitrage transaction there might be several tokens involved but in the end the arbitrageur gains profit from a single token (this is the most basic analysis of arbitrage transactions, it's possible that the user gains profit from multiple tokens which occur in more complex arbitrages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _total_profit(_address: str):\n",
    "    return arb_df.loc[arb_df.account_address == _address, 'profit_amount'].sum()\n",
    "\n",
    "\n",
    "def _token_use(token_column: str):\n",
    "    _tokens = arb_df[token_column].apply(lambda lst: list(dict.fromkeys(lst.split(\";\"))))\n",
    "\n",
    "    _token_uses = {}\n",
    "    for row, _cnt in _tokens.value_counts().iteritems():\n",
    "        for idx in row:\n",
    "            _token_uses[idx] = _token_uses.get(idx, 0) + _cnt\n",
    "\n",
    "    return pd.DataFrame(_token_uses.values(), index=_token_uses.keys())\n",
    "\n",
    "\n",
    "def _get_token_degrees():\n",
    "    input_tokens_degree = pd.DataFrame(columns=['transaction_hash', 'degree'], dtype='object')\n",
    "    output_tokens_degree = pd.DataFrame(columns=['transaction_hash', 'degree'], dtype='object')\n",
    "    output_tokens_degree['transaction_hash'] = arb_df['transaction_hash']\n",
    "    input_tokens_degree['transaction_hash'] = arb_df['transaction_hash']\n",
    "    output_tokens_degree['degree'] = arb_df['output_tokens_address'].apply(\n",
    "        lambda lst: len(list(dict.fromkeys(lst.split(\";\")))))\n",
    "    input_tokens_degree['degree'] = arb_df['input_tokens_address'].apply(\n",
    "        lambda lst: len(list(dict.fromkeys(lst.split(\";\")))))\n",
    "    return input_tokens_degree, output_tokens_degree\n",
    "\n",
    "\n",
    "from tokens.name_tags import get_name_tag\n",
    "\n",
    "\n",
    "def _get_name_tags(addresses):\n",
    "    _public_name_tags = {}\n",
    "\n",
    "    for address in addresses:\n",
    "        _public_name_tags[address] = get_name_tag(_address=address)\n",
    "\n",
    "    return _public_name_tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Used Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "profitable_input_tokens = _token_use('input_tokens_address')\n",
    "profitable_output_tokens = _token_use('output_tokens_address')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_input_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profitable_output_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference between input and output degrees of arbitrage transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "any(profitable_output_tokens - profitable_input_tokens != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input and output degrees of the tokens are equal.\n",
    "\n",
    "### Transaction Degree Analysis\n",
    "Now, let's check the degree vvalue of arbitrage transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del profitable_output_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_degree, _ = _get_token_degrees()\n",
    "tokens_degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_degree.hist('degree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most profitable tokens\n",
    "# profitable_input_tokens\n",
    "\n",
    "MIN_PROFITABLE_TXN_CNT = 1000\n",
    "\n",
    "most_profitable_tokens = profitable_input_tokens.drop(\n",
    "    labels=profitable_input_tokens[profitable_input_tokens.values < MIN_PROFITABLE_TXN_CNT].index).sort_values(by=[0],\n",
    "                                                                                                               ascending=False)[\n",
    "                         :20]\n",
    "\n",
    "public_name_tags = _get_name_tags(most_profitable_tokens.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bar(ax, x, y, _rotation=45, _width=0.3):\n",
    "    ax.bar(x, y, width=_width)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(x, rotation=_rotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.transforms import ScaledTranslation\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(20, 10))\n",
    "\n",
    "bar(ax1, most_profitable_tokens.index.map(public_name_tags), most_profitable_tokens.values.squeeze())\n",
    "bar(ax2, most_profitable_tokens.index.map(public_name_tags), most_profitable_tokens.values.squeeze())\n",
    "\n",
    "ax1.set_ylim(most_profitable_tokens.values[0] - 5000, most_profitable_tokens.values[0] + 5000)  # outliers only\n",
    "ax2.set_ylim(0, most_profitable_tokens.values[1] + 2000)  # most of the data\n",
    "\n",
    "ax1.spines['bottom'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "ax2.xaxis.tick_bottom()\n",
    "\n",
    "d = .010  # how big to make the diagonal lines in axes coordinates\n",
    "# arguments to pass to plot, just so we don't keep repeating them\n",
    "kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "ax1.plot((-d, +d), (-d, +d), **kwargs)  # top-left diagonal\n",
    "ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "\n",
    "kwargs.update(transform=ax2.transAxes)  # switch to the bottom axes\n",
    "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal\n",
    "\n",
    "ax1.set_title(\"Most used tokens for arbitrage\")\n",
    "ax2.set_xlabel(\"Token public name tag\")\n",
    "f.text(0.08, 0.5, 'Number of arbitrages', va='center', rotation='vertical')\n",
    "\n",
    "# https://stackoverflow.com/questions/28615887/how-to-move-a-tick-label-in-matplotlib\n",
    "# Create offset transform by 5 points in x direction\n",
    "dx = -0.2\n",
    "dy = 0.\n",
    "offset = ScaledTranslation(dx, dy, f.dpi_scale_trans)\n",
    "\n",
    "for label in ax2.get_xmajorticklabels():\n",
    "    label.set_transform(label.get_transform() + offset)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_profitable_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most used token is WETH. This is because arbitrageurs usually buy an arbitrage asset using ETH and gain the profit by selling them in ETH.\n",
    "This might be because the WETH-TOKEN pools are more common in the exchanges.\n",
    "The three latter places belong to stable coins: USDC, USDT and DAI\n",
    "In the most used tokens we can see a lot of rather lesser known and stable coins: SHIB, FRAX, FunFair etc.\n",
    "Note that originally we only stored and counted the profit token which is usually WETH. But as mentioned before, the arbitrage opportunity is not a result of instability in WETH, rather in the instability of a certain token which is then seized using the WETH pool.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most Active Addresses\n",
    "\n",
    "In this part we take a look at the most active arbitrageurs i.e. the addresses that have the most arbitrage transactions.\n",
    "We can use this data along with the most profitable addresses to see if there is any relation between number of txns and profit??\n",
    "\n",
    "Get the distribution of the number of transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most arbitrageurs\n",
    "MIN_ARBITRAGE_TXN_CNT = 2000\n",
    "\n",
    "arbitrageurs = arb_df['account_address'].value_counts()\n",
    "\n",
    "most_active_arbitrageurs = arbitrageurs.drop(labels=arbitrageurs[arbitrageurs.values < MIN_ARBITRAGE_TXN_CNT].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "bar(ax1, most_active_arbitrageurs.index, most_active_arbitrageurs.values, _rotation=60, _width=0.4)\n",
    "\n",
    "ax1.set_title(\"Most Frequent Arbitrageurs\")\n",
    "ax1.set_xlabel(\"Arbitrageur Address\")\n",
    "\n",
    "# https://stackoverflow.com/questions/28615887/how-to-move-a-tick-label-in-matplotlib\n",
    "# Create offset transform by 5 points in x direction\n",
    "dx = -0.7\n",
    "dy = 0.\n",
    "offset = ScaledTranslation(dx, dy, f.dpi_scale_trans)\n",
    "\n",
    "for label in ax1.get_xmajorticklabels():\n",
    "    label.set_transform(label.get_transform() + offset)\n",
    "\n",
    "f.text(0.08, 0.5, 'Number of arbitrages', va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_active_arbitrageurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Addresses Analysis\n",
    "\n",
    "### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 10))\n",
    "arb_cnt = arbitrageurs.groupby(arbitrageurs).count()[:100]\n",
    "labels = [str(i) for i in arb_cnt.index]\n",
    "plt.bar(labels, arb_cnt.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel(\"Number of arbitrages\")\n",
    "plt.ylabel(\"Number of arbitrageurs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much can be interpreted from the above plot, yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we ignore the single transaction arbitrageurs?\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "arb_cnt = arbitrageurs.groupby(arbitrageurs).count()[1:100]\n",
    "plt.bar(arb_cnt.index, arb_cnt.values)\n",
    "plt.xlabel(\"Number of arbitrages\")\n",
    "plt.ylabel(\"Number of arbitrageurs\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ratio of arbitrage transactions\n",
    "The percentage of transactions that are arbitrage for each address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Accounts data\n",
    "Get number of transactions of each address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "adr_db_path = \"../db/addresses/\"\n",
    "number_of_files = len(os.listdir(adr_db_path))\n",
    "column_names = ['txn_cnt_' + str(i) for i in range(number_of_files)]\n",
    "adr_df = pd.DataFrame(columns=['address'], dtype='object')\n",
    "\n",
    "i = 0\n",
    "for file_name in os.listdir(adr_db_path):\n",
    "    print(datetime.now(), file_name)\n",
    "    temp_adr_df = pd.read_csv(adr_db_path + file_name, names=['address', 'txn_cnt_' + str(i)], index_col=False)\n",
    "    temp_adr_df = temp_adr_df.groupby(by=['address']).sum()\n",
    "    adr_df = adr_df.merge(temp_adr_df, how='outer', on='address')\n",
    "    print(datetime.now(), file_name, 'end')\n",
    "    i += 1\n",
    "\n",
    "adr_df.fillna(0)\n",
    "adr_df['txn_cnt'] = adr_df[column_names].sum(axis=1)\n",
    "adr_df.drop(columns=column_names, inplace=True)\n",
    "adr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_df[adr_df['txn_cnt_0'] > np.mean(adr_df[adr_df['txn_cnt_0'] > 1])].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "### Benefit gained through arbitrage per address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## Time Analysis of Arbitrage Transactions\n",
    "### Frequency for the Blockchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_df = arb_df.groupby([arb_df['time_stamp'].dt.year, arb_df['time_stamp'].dt.month]).count()[\n",
    "    ['block_number', 'transaction_hash']]\n",
    "month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "month_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del month_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df = arb_df.groupby([arb_df['time_stamp'].dt.date]).count()[['block_number', 'transaction_hash']]\n",
    "day_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(day_df['block_number'])\n",
    "del day_df\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hourly\n",
    "hour_df = arb_df.groupby([arb_df['time_stamp'].dt.date, arb_df['time_stamp'].dt.hour]).count()[\n",
    "    ['block_number', 'transaction_hash']]\n",
    "hour_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hour_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_list = list(hour_df['block_number'])\n",
    "\n",
    "grp_val = 24\n",
    "\n",
    "plt.plot([sum(hour_list[i:i + grp_val]) for i in range(0, len(hour_list), grp_val)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del hour_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Minute\n",
    "minute_df = \\\n",
    "arb_df.groupby([arb_df['time_stamp'].dt.date, arb_df['time_stamp'].dt.hour, arb_df['time_stamp'].dt.minute]).count()[\n",
    "    ['block_number', 'transaction_hash']]\n",
    "minute_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minute_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del minute_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency for Each Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Daily Frequency\n",
    "acc_freq_df = arb_df.loc[arb_df['account_address'].isin(most_active_arbitrageurs.index)].groupby(\n",
    "    [arb_df['account_address'], arb_df['time_stamp'].dt.date]).count()[['block_number', 'transaction_hash']]\n",
    "acc_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(acc_freq_df.index.get_level_values(0).unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frequency for Each Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Block position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## Arbitrage input output degree Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "## Most used protocols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "protocol_uses = _protocol_use()\n",
    "protocol_uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_protocol_uses = {}\n",
    "\n",
    "for protocol, cnt in protocol_uses.items():\n",
    "    normalized_protocol_uses[protocol] = cnt / swp_df.protocol.value_counts()[protocol]\n",
    "\n",
    "normalized_protocol_uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax1.bar(protocol_uses.keys(), protocol_uses.values(), width=0.5)\n",
    "ax1.set_xticklabels(protocol_uses.keys(), rotation=45)\n",
    "ax1.set_title(\"Most Used Protocols (Not Normalized)\")\n",
    "ax1.set_xlabel(\"Protocol\")\n",
    "f.text(0.08, 0.5, 'Number of arbitrages', va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1) = plt.subplots(1, 1, figsize=(20, 10))\n",
    "\n",
    "ax1.bar(normalized_protocol_uses.keys(), normalized_protocol_uses.values(), width=0.5)\n",
    "ax1.set_xticklabels(normalized_protocol_uses.keys(), rotation=45)\n",
    "ax1.set_title(\"Most Used Protocols (Normalized)\")\n",
    "ax1.set_xlabel(\"Protocol\")\n",
    "f.text(0.08, 0.5, 'Number of arbitrages', va='center', rotation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "## Topological Analysis of Arbitrageur Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## Mempool wait time for arbitrage transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
